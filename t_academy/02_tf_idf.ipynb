{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = [\n",
    "  '먹고 싶은 사과', # 문서0 \n",
    "  '먹고 싶은 바나나', # 문서1\n",
    "  '길고 노란 바나나 바나나', # 문서2 \n",
    "  '저는 과일이 좋아요' # 문서3 \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vect = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<4x9 sparse matrix of type '<class 'numpy.int64'>'\n\twith 12 stored elements in Compressed Sparse Row format>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "countvect = vect.fit_transform(docs)\n",
    "countvect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 1 0 1 1 0 0]\n",
      " [0 0 0 1 1 0 1 0 0]\n",
      " [0 1 1 0 2 0 0 0 0]\n",
      " [1 0 0 0 0 0 0 1 1]] \n",
      "\n",
      "{'먹고': 3, '싶은': 6, '사과': 5, '바나나': 4, '길고': 1, '노란': 2, '저는': 7, '과일이': 0, '좋아요': 8}\n"
     ]
    }
   ],
   "source": [
    "print(countvect.toarray(), '\\n')\n",
    "print(vect.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>과일이</th>\n      <th>길고</th>\n      <th>노란</th>\n      <th>먹고</th>\n      <th>바나나</th>\n      <th>사과</th>\n      <th>싶은</th>\n      <th>저는</th>\n      <th>좋아요</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>doc1</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>doc2</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>doc3</th>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>doc4</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "      과일이  길고  노란  먹고  바나나  사과  싶은  저는  좋아요\ndoc1    0   0   0   1    0   1   1   0    0\ndoc2    0   0   0   1    1   0   1   0    0\ndoc3    0   1   1   0    2   0   0   0    0\ndoc4    1   0   0   0    0   0   0   1    1"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "countvect_df = pd.DataFrame(countvect.toarray(), columns = sorted(vect.vocabulary_))\n",
    "countvect_df.index = ['doc1', 'doc2', 'doc3', 'doc4']\n",
    "countvect_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "array([[1.        , 0.66666667, 0.        , 0.        ],\n       [0.66666667, 1.        , 0.47140452, 0.        ],\n       [0.        , 0.47140452, 1.        , 0.        ],\n       [0.        , 0.        , 0.        , 1.        ]])"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "cosine_similarity(countvect_df, countvect_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vect = TfidfVectorizer()\n",
    "tfvect = vect.fit(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>과일이</th>\n      <th>길고</th>\n      <th>노란</th>\n      <th>먹고</th>\n      <th>바나나</th>\n      <th>사과</th>\n      <th>싶은</th>\n      <th>저는</th>\n      <th>좋아요</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>doc1</th>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.526405</td>\n      <td>0.00000</td>\n      <td>0.667679</td>\n      <td>0.526405</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n    </tr>\n    <tr>\n      <th>doc2</th>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.577350</td>\n      <td>0.57735</td>\n      <td>0.000000</td>\n      <td>0.577350</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n    </tr>\n    <tr>\n      <th>doc3</th>\n      <td>0.00000</td>\n      <td>0.47212</td>\n      <td>0.47212</td>\n      <td>0.000000</td>\n      <td>0.74445</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n    </tr>\n    <tr>\n      <th>doc4</th>\n      <td>0.57735</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.000000</td>\n      <td>0.00000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.57735</td>\n      <td>0.57735</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "          과일이       길고       노란        먹고  ...        사과        싶은       저는      좋아요\ndoc1  0.00000  0.00000  0.00000  0.526405  ...  0.667679  0.526405  0.00000  0.00000\ndoc2  0.00000  0.00000  0.00000  0.577350  ...  0.000000  0.577350  0.00000  0.00000\ndoc3  0.00000  0.47212  0.47212  0.000000  ...  0.000000  0.000000  0.00000  0.00000\ndoc4  0.57735  0.00000  0.00000  0.000000  ...  0.000000  0.000000  0.57735  0.57735\n\n[4 rows x 9 columns]"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidv_df = pd.DataFrame(tfvect.transform(docs).toarray(), columns = sorted(vect.vocabulary_))\n",
    "tfidv_df.index = ['doc1', 'doc2', 'doc3', 'doc4']\n",
    "tfidv_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "array([[1.        , 0.60784064, 0.        , 0.        ],\n       [0.60784064, 1.        , 0.42980824, 0.        ],\n       [0.        , 0.42980824, 1.        , 0.        ],\n       [0.        , 0.        , 0.        , 1.        ]])"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarity(tfidv_df, tfidv_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vect = TfidfVectorizer(max_features = 4)\n",
    "tfvect = vect.fit(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>과일이</th>\n      <th>먹고</th>\n      <th>바나나</th>\n      <th>싶은</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>doc1</th>\n      <td>0.0</td>\n      <td>0.707107</td>\n      <td>0.00000</td>\n      <td>0.707107</td>\n    </tr>\n    <tr>\n      <th>doc2</th>\n      <td>0.0</td>\n      <td>0.577350</td>\n      <td>0.57735</td>\n      <td>0.577350</td>\n    </tr>\n    <tr>\n      <th>doc3</th>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>1.00000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>doc4</th>\n      <td>1.0</td>\n      <td>0.000000</td>\n      <td>0.00000</td>\n      <td>0.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "      과일이        먹고      바나나        싶은\ndoc1  0.0  0.707107  0.00000  0.707107\ndoc2  0.0  0.577350  0.57735  0.577350\ndoc3  0.0  0.000000  1.00000  0.000000\ndoc4  1.0  0.000000  0.00000  0.000000"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidv_df = pd.DataFrame(tfvect.transform(docs).toarray(), columns = sorted(vect.vocabulary_))\n",
    "tfidv_df.index = ['doc1', 'doc2', 'doc3', 'doc4']\n",
    "tfidv_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>adult</th>\n      <th>belongs_to_collection</th>\n      <th>budget</th>\n      <th>genres</th>\n      <th>homepage</th>\n      <th>id</th>\n      <th>imdb_id</th>\n      <th>original_language</th>\n      <th>original_title</th>\n      <th>overview</th>\n      <th>popularity</th>\n      <th>poster_path</th>\n      <th>production_companies</th>\n      <th>production_countries</th>\n      <th>release_date</th>\n      <th>revenue</th>\n      <th>runtime</th>\n      <th>spoken_languages</th>\n      <th>status</th>\n      <th>tagline</th>\n      <th>title</th>\n      <th>video</th>\n      <th>vote_average</th>\n      <th>vote_count</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>False</td>\n      <td>{'id': 10194, 'name': 'Toy Story Collection', ...</td>\n      <td>30000000</td>\n      <td>[{'id': 16, 'name': 'Animation'}, {'id': 35, '...</td>\n      <td>http://toystory.disney.com/toy-story</td>\n      <td>862</td>\n      <td>tt0114709</td>\n      <td>en</td>\n      <td>Toy Story</td>\n      <td>Led by Woody, Andy's toys live happily in his ...</td>\n      <td>21.946943</td>\n      <td>/rhIRbceoE9lR4veEXuwCC2wARtG.jpg</td>\n      <td>[{'name': 'Pixar Animation Studios', 'id': 3}]</td>\n      <td>[{'iso_3166_1': 'US', 'name': 'United States o...</td>\n      <td>1995-10-30</td>\n      <td>373554033.0</td>\n      <td>81.0</td>\n      <td>[{'iso_639_1': 'en', 'name': 'English'}]</td>\n      <td>Released</td>\n      <td>NaN</td>\n      <td>Toy Story</td>\n      <td>False</td>\n      <td>7.7</td>\n      <td>5415.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>False</td>\n      <td>NaN</td>\n      <td>65000000</td>\n      <td>[{'id': 12, 'name': 'Adventure'}, {'id': 14, '...</td>\n      <td>NaN</td>\n      <td>8844</td>\n      <td>tt0113497</td>\n      <td>en</td>\n      <td>Jumanji</td>\n      <td>When siblings Judy and Peter discover an encha...</td>\n      <td>17.015539</td>\n      <td>/vzmL6fP7aPKNKPRTFnZmiUfciyV.jpg</td>\n      <td>[{'name': 'TriStar Pictures', 'id': 559}, {'na...</td>\n      <td>[{'iso_3166_1': 'US', 'name': 'United States o...</td>\n      <td>1995-12-15</td>\n      <td>262797249.0</td>\n      <td>104.0</td>\n      <td>[{'iso_639_1': 'en', 'name': 'English'}, {'iso...</td>\n      <td>Released</td>\n      <td>Roll the dice and unleash the excitement!</td>\n      <td>Jumanji</td>\n      <td>False</td>\n      <td>6.9</td>\n      <td>2413.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>False</td>\n      <td>{'id': 119050, 'name': 'Grumpy Old Men Collect...</td>\n      <td>0</td>\n      <td>[{'id': 10749, 'name': 'Romance'}, {'id': 35, ...</td>\n      <td>NaN</td>\n      <td>15602</td>\n      <td>tt0113228</td>\n      <td>en</td>\n      <td>Grumpier Old Men</td>\n      <td>A family wedding reignites the ancient feud be...</td>\n      <td>11.7129</td>\n      <td>/6ksm1sjKMFLbO7UY2i6G1ju9SML.jpg</td>\n      <td>[{'name': 'Warner Bros.', 'id': 6194}, {'name'...</td>\n      <td>[{'iso_3166_1': 'US', 'name': 'United States o...</td>\n      <td>1995-12-22</td>\n      <td>0.0</td>\n      <td>101.0</td>\n      <td>[{'iso_639_1': 'en', 'name': 'English'}]</td>\n      <td>Released</td>\n      <td>Still Yelling. Still Fighting. Still Ready for...</td>\n      <td>Grumpier Old Men</td>\n      <td>False</td>\n      <td>6.5</td>\n      <td>92.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>False</td>\n      <td>NaN</td>\n      <td>16000000</td>\n      <td>[{'id': 35, 'name': 'Comedy'}, {'id': 18, 'nam...</td>\n      <td>NaN</td>\n      <td>31357</td>\n      <td>tt0114885</td>\n      <td>en</td>\n      <td>Waiting to Exhale</td>\n      <td>Cheated on, mistreated and stepped on, the wom...</td>\n      <td>3.859495</td>\n      <td>/16XOMpEaLWkrcPqSQqhTmeJuqQl.jpg</td>\n      <td>[{'name': 'Twentieth Century Fox Film Corporat...</td>\n      <td>[{'iso_3166_1': 'US', 'name': 'United States o...</td>\n      <td>1995-12-22</td>\n      <td>81452156.0</td>\n      <td>127.0</td>\n      <td>[{'iso_639_1': 'en', 'name': 'English'}]</td>\n      <td>Released</td>\n      <td>Friends are the people who let you be yourself...</td>\n      <td>Waiting to Exhale</td>\n      <td>False</td>\n      <td>6.1</td>\n      <td>34.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>False</td>\n      <td>{'id': 96871, 'name': 'Father of the Bride Col...</td>\n      <td>0</td>\n      <td>[{'id': 35, 'name': 'Comedy'}]</td>\n      <td>NaN</td>\n      <td>11862</td>\n      <td>tt0113041</td>\n      <td>en</td>\n      <td>Father of the Bride Part II</td>\n      <td>Just when George Banks has recovered from his ...</td>\n      <td>8.387519</td>\n      <td>/e64sOI48hQXyru7naBFyssKFxVd.jpg</td>\n      <td>[{'name': 'Sandollar Productions', 'id': 5842}...</td>\n      <td>[{'iso_3166_1': 'US', 'name': 'United States o...</td>\n      <td>1995-02-10</td>\n      <td>76578911.0</td>\n      <td>106.0</td>\n      <td>[{'iso_639_1': 'en', 'name': 'English'}]</td>\n      <td>Released</td>\n      <td>Just When His World Is Back To Normal... He's ...</td>\n      <td>Father of the Bride Part II</td>\n      <td>False</td>\n      <td>5.7</td>\n      <td>173.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "   adult  ... vote_count\n0  False  ...     5415.0\n1  False  ...     2413.0\n2  False  ...       92.0\n3  False  ...       34.0\n4  False  ...      173.0\n\n[5 rows x 24 columns]"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"/Users/yuhwanseung/Documents/movie_datasets\"\n",
    "data = pd.read_csv(os.path.join(path, 'movies_metadata.csv'), low_memory = False)\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "Index(['adult', 'belongs_to_collection', 'budget', 'genres', 'homepage', 'id',\n       'imdb_id', 'original_language', 'original_title', 'overview',\n       'popularity', 'poster_path', 'production_companies',\n       'production_countries', 'release_date', 'revenue', 'runtime',\n       'spoken_languages', 'status', 'tagline', 'title', 'video',\n       'vote_average', 'vote_count'],\n      dtype='object')"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "(44512, 24)"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data[data['overview'].notnull()].reset_index(drop = True)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.loc[0:20000].reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20001, 47665)\n"
     ]
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer(stop_words = 'english')\n",
    "tfidf_matrix = tfidf.fit_transform(data['overview'])\n",
    "print(tfidf_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "array([[1.    , 0.0158, 0.    , ..., 0.0083, 0.0172, 0.    ],\n       [0.0158, 1.    , 0.0492, ..., 0.0057, 0.008 , 0.    ],\n       [0.    , 0.0492, 1.    , ..., 0.    , 0.    , 0.    ],\n       ...,\n       [0.0083, 0.0057, 0.    , ..., 1.    , 0.0144, 0.    ],\n       [0.0172, 0.008 , 0.    , ..., 0.0144, 1.    , 0.0183],\n       [0.    , 0.    , 0.    , ..., 0.    , 0.0183, 1.    ]])"
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "cosine_matrix = cosine_similarity(tfidf_matrix, tfidf_matrix)\n",
    "np.round(cosine_matrix,4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "movie2id = defaultdict()\n",
    "for idx, column in enumerate(data['title']):\n",
    "    movie2id[idx] = column\n",
    "\n",
    "id2movie = defaultdict()\n",
    "for idx, column in movie2id.items():\n",
    "    id2movie[column] = idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "data": {
      "text/plain": "[(15282, 0.5262275451171008),\n (2979, 0.463276799830381),\n (10271, 0.2797390476075632),\n (8303, 0.20078538664316947),\n (1058, 0.18287334034120212),\n (11367, 0.15712074193481165),\n (1916, 0.15288512626542436),\n (3039, 0.1433450408051554),\n (483, 0.13765225108436677),\n (11573, 0.1337032693869044)]"
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = id2movie['Toy Story']\n",
    "print(idx)\n",
    "\n",
    "sim_scores = [(i,c) for i,c in enumerate(cosine_matrix[idx]) if i != idx]\n",
    "sim_scores = sorted(sim_scores, key = lambda x : x[1], reverse = True)\n",
    "sim_scores[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "[('Toy Story 3', 0.5262275451171008),\n ('Toy Story 2', 0.463276799830381),\n ('The 40 Year Old Virgin', 0.2797390476075632),\n ('The Champ', 0.20078538664316947),\n ('Rebel Without a Cause', 0.18287334034120212),\n ('For Your Consideration', 0.15712074193481165),\n ('Condorman', 0.15288512626542436),\n ('Man on the Moon', 0.1433450408051554),\n ('Malice', 0.13765225108436677),\n ('Factory Girl', 0.1337032693869044)]"
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim_scores = [(movie2id[i], score) for i, score in sim_scores[:10]]\n",
    "sim_scores"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}